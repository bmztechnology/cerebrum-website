# K-Nearest Neighbors (KNN): Pattern Matching

## I. Executive Summary

**K-Nearest Neighbors** is a non-parametric, lazy learning algorithm. It assumes that "History Repeats Itself." If the market state today (Vol, Trend, RSI) looks like 5 days in the past, the price action tomorrow will likely resemble the price action that followed those 5 days. It is the algorithmic equivalent of looking at a chart and saying "I've seen this pattern before."

## II. Formal Definitions

### Definition 2.1 (The Algorithm)
1.  Store all training vectors $X_{train}$.
2.  Receive new vector $x_{new}$.
3.  Calculate Distance $d(x_{new}, x_i)$ (Euclidean, Manhattan).
4.  Select top $K$ closest neighbors.
5.  Prediction = Average($y$ of Neighbors).

### Definition 2.2 (Distance Metric)
Euclidean: $d = \sqrt{\sum (x_a - x_b)^2}$.
Cosine Similarity: $\cos(\theta) = \frac{A \cdot B}{||A|| ||B||}$.
(Cosine is better for shape matching, ignoring amplitude).

## III. Theoretical Framework

### 3.1 Non-Linearity
KNN captures arbitrary non-linear islands.
If "High Vol + Low RSI" is Bullish, but "Low Vol + Low RSI" is Bearish, KNN sees this immediately by neighborhood. Linear regression fails.

### 3.2 The Curse of Dimensionality
As dimensions $D$ increase, "distance" loses meaning (everything is far from everything).
KNN fails in high dimensions ($D > 20$).
Requires dimensionality reduction (PCA) first.

## IV. Strategic Applications

### 4.1 Analog Trading
"Find the top 10 historical days most similar to Today."
Plot their forward returns.
If 8/10 went up, Buy.
This is heavily used by Quant Funds for "Event Trading" (e.g., Fed Days).

### 4.2 Dynamic Volatility Prediction
Predicting 1-hour volatility.
Find nearest neighbors in "Time of Day" and "Recent Vol" space.
Average their future realized vol.
Works better than GARCH for intraday microstructure.

## V. Exercises

**Exercise 1 (Selecting K):**
$K=1$: Nearest Neighbor. High Variance (chases noise).
$K=N$: Average of all history. High Bias (Flat line).
Optimal $K \approx \sqrt{N}$.

**Exercise 2 (Lookahead Bias):**
When finding neighbors, ensure you don't use data from the neighbor's *future* to match the current state.
Standard backtesting pitfall.

## VI. References
-   Cover, T., & Hart, P. *Nearest Neighbor Pattern Classification*.
-   Duda, R.O. *Pattern Classification*.
